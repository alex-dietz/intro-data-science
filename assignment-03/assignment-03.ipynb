{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-1316 Introduction to *Urban* Data Science \n",
    "\n",
    "\n",
    "## Assignment 3: Prediction / Inference\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``Instructions``\n",
    "\n",
    "This assignment puts together what you learned in **Weeks 6-7**. Assignment 3 will build upon what you did in Assignment 2.  \n",
    "\n",
    "_Note:_ Go through **labs and homeworks 05-06** before starting this assignment. \n",
    "\n",
    "#### 1.1 Submission\n",
    "\n",
    "Please submit the results by Brightspace under **Assignment 03**, using a single file as example,\n",
    "\n",
    "```text\n",
    "firstname_secondname_thirdname_lastname_03.html\n",
    "\n",
    "```\n",
    "\n",
    "**If your file is not named in lowercase letters as mentioned above, your assignment will not be read by the script that works to compile 200 assignments and you will miss out on the grades. I don't want that, so be exceptionally careful that you name it properly. Don't worry if you spelled your name incorrectly. I want to avoid a situation where I have 200 assignments all called assignment_03.html**\n",
    "\n",
    "Please **do not** submit any data or files other than the ``html file``.\n",
    "\n",
    "Don't worry about your submission _rendering without the images_ **after** you submitted the file on brightspace. That is a brigthspace related issue of viewing your own submission but when I download all assignments as a batch file, I get all your images and code as you intended to submit. So make sure that your html shows everything you want us to see **before you submit**. \n",
    "\n",
    "#### 1.2 How do you convert to HTML? \n",
    "\n",
    "There are 2 ways, \n",
    "\n",
    "1. from a running notebook, you can convert it into html by clicking on the file tab on the main menu of Jupyter Lab \n",
    "    * File &rightarrow; Export Notebooks as... &rightarrow; Export Notebook to HTML\n",
    "2. go to terminal or command line and type\n",
    "    * ``jupyter nbconvert --to html <notebook_name>.ipynb  ``\n",
    "\n",
    "#### 1.3 Learning Objectives\n",
    "\n",
    "This assignment is designed to support one learning objective. After completing the following exercises you will be able to:\n",
    "\n",
    "* Explain the outcome of your models and relate them to your hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Problem``\n",
    "\n",
    "`Problem Statement`: While we all aspire to minimise crime, poverty, segregation or other inequitable and undesirable outcomes in society, it is necessary to first understand the severity of the issue and some of the most contributing factors or complex patterns that we may not completely understand without analysing the underlying data. It may come as a surprise, but a lot of these outcomes are ubiquitous in many parts of The Hague. For example, many neighbourhoods are quite poor, do not have access to public transport services or enough amenities and resources. A lot of these lacking infrastructure services result in complex socio-economic outcomes like gentrification, segregation, lack of jobs, excessive reliance on personal vehicle etc. Pinpointing the exact causes of such observations is impossible, as these are highly nuanced and complex issues. However, factors such as gross income, economic disparity, liveability and government infrastructure/support are often strong indicators. For example, it is widely believed that there’s an increase in crime in regions that have a large variance in citizens’ income levels. What is more, these neighbourhoods tend to cluster in space.\n",
    "\n",
    "`What we expect`: Consider your hypothesis from **assignment 02**. In this assignment you are tasked with inspecting either 1). if there are natural clusters or dimensions in your data (an unsupervised learning - clustering problem), or 2). factors that may be correlated and/or contributing to a variable of your interest in the data (e.g., crime, poverty, liveability, etc). You should explore the same datasets from assignment 02 (they are mentioned again for clarity, below). Perform exploratory data analysis, iteratively refine your questions and chosen datasets, and produce plots to understand and communicate your findings. You may have done most of the exploration in assignment 02, so choosing the same hypothesis will save you time. You can use the contents of assignment-02. You are free to come up with a different hypothesis, but that would mean more time to go through data cleaning and EDA. I strongly advise to build upon assignment-02 and make certain improvements based on the feedback received. \n",
    "\n",
    "Through this exercise, we expect you to think about your models in this assignment. What are the overall strengths and weaknesses of your models? Continue to improve your model to the best of your abilities. Lastly, comment on any additional ideas you have for a model that may be able to perform better, even if these ideas are not possible by any model that we have learned about in the course – for example, explain what type of information you wish your model could use, and how do you wish it could leverage that information. This doesn’t have to be explained in mathematical terms or theory, but the goal is to think about current limitations of models and how you wish to improve upon them.\n",
    "\n",
    "`Example`\n",
    "If I look at crime, I'd start by looking at surface-level factors that may be correlated with crime, the conditions of a neighbourhood: presence of shops, schools, amenities. I'd start thinking about the following non-exhaustive list of questions: \n",
    "- Are certain crimes more likely to occur where there is a dearth of amenities? \n",
    "- Are there any characteristic clusters of high or low crime in space? \n",
    "- Is there any correlation at all with busy areas and the locations of crimes? Or with rich areas and crime? \n",
    "- How should I measure the presence of amentities or the richness of a neighbourhood? \n",
    "\n",
    "`Assignment Goal`: Improving societal conditions for several communities is a complex, difficult, and slow process. You may not even have variables in your hypothesis that logically completely correlate with your variable of choice. But try! This is only practice. We want students to explore data and make statistical predictions in an area that is vastly affected by many confounding, real-world complex factors. The goal is for students to illustrate learned skills that align with our course goals. The primary goal of this project is to explain the outcomes of an event you observed and hypothesized in the datasets related to The Hague. Any piece of information from The Hague can be used to perform this analysis, but the suggested feature set should include the variables on the demographic information of The Hague (see below for datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Data``\n",
    "\n",
    "As part of the assignment files, I have provided you with the **first dataset**: the shapefiles of The Hague. After you unzip the data, we’ll work with the files of the form ``neighborhoods.xxx``, in all the different geographic formats. Put the data in a convenient location on your computer or laptop, ideally in a folder called **data** which is next to this **jupyter notebook**. I recommend taking a look at the file with format `.json` in a text editor like _atom_ for any system or notepad++ for windows. These will also make your life easy for everything else on your computer. Make sure you’ve set your working directory in the [correct manner](https://www.delftstack.com/howto/python/relative-path-in-python/).\n",
    "\n",
    "It’s a big file and it may take a while to load onto your laptop and into Python (running on the jupyter labs environment). \n",
    "\n",
    "As mentioned above in the problem introduction, you will use at least two datasets.\n",
    "\n",
    "1. **First Dataset:** Download Shapefiles provided with the assignment\n",
    "2. **Second Dataset:** Get a second dataset of your choice from The Hague city region using the links below (curate them as you like)\n",
    "\n",
    "#### More Data Sources\n",
    "\n",
    "You can find more data sources on Cities and Population, Climate indicators and Land-use in the following links.\n",
    "\n",
    "Mikhail Sirenko has prepared the **first dataset** shapefiles with love and care so that you can connect it with either [Den Haag Cijfers](https://denhaag.incijfers.nl/jive) or [CBS](https://www.cbs.nl/nl-nl/reeksen/kerncijfers-wijken-en-buurten-2004-2020) datasets without having to clean any data. For the rest of the datasets, you may need to clean up.\n",
    "\n",
    "_Note:_ Data from CBS is only complete upto 2017. You will have to subset the data on municpality using the variable name `gm_naam = 's-Gravenhage` and then subset on neighbourhood resolution using variable name `recs = Buurt` to get the data that can match the shapefiles we have provided. \n",
    "\n",
    "* https://denhaag.incijfers.nl/jive (available in English on the website)\n",
    "* https://www.cbs.nl/nl-nl/reeksen/kerncijfers-wijken-en-buurten-2004-2020\n",
    "* http://citypopulation.de/ \n",
    "* https://www.census.gov/programs-surveys/geography.html \n",
    "* https://www.eea.europa.eu/data-and-maps \n",
    "* http://download.geofabrik.de/\n",
    "\n",
    "#### In case you get more data as shapefiles, and want to play with projections, a nice guide for it is [here](https://automating-gis-processes.github.io/CSC18/lessons/L2/projections.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Tasks``\n",
    "\n",
    "For your convenience, the assignment has been divided into the following tasks, \n",
    "\n",
    "0. Use Assignment 2 as a base for this assignment.\n",
    "1. Build a regression or clustering model to analyse your hypothesis. \n",
    "2. Use EDA, plot results, and make refinements to your models. (assignment 2 can be used here as a basis for your models - save time and remember the process is not linear!)\n",
    "3. If you choose the regression path, perform error analyses, noting the best features, worst features, and any trends in supervised learning. If you choose the clustering path, explore which variables contribute the most to explaining the clusters using a principle component analysis. Report your results and provide in-depth analysis of the models using quick notes in markdown cells. \n",
    "4. Discuss your results, model weaknesses and future ideas for improvements. \n",
    "\n",
    "**A tip: you can use variations in the year of the data to use extra data in your observations. Does your model work for year 2016 and predict or cluster well for 2017?** \n",
    "\n",
    "***Remember to always document your code! Justify everything you do (cleaning data, analysisng data, exploring data, defining hypothesis or measurements, etc.) using markdown cells as you go through the notebook.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Start your analysis``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #I use the geopandas read_file function to read the shapefile.\n",
    "den_haag_neighborhoods = gpd.read_file(\"data/neighborhoods.shp\")\n",
    "# I check the data by printing the first 5 rows of the data.\n",
    "den_haag_neighborhoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that my shapefile provides me with the neighbourhoods of The Hague. It also provides me with the geometry of the neighbourhoods. This is important for plotting the data later on. I can identify the different neighborhoods with the columns \"neighb_cbs\" or \"neighb_cijf\", which facilitates the use with data from CBS or Den Haag Cijfers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get a quick overview of the spatial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EDA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x_train,y_train):\n",
    "    # build the least squares model\n",
    "    toyregr = linear_model.LinearRegression()\n",
    "\n",
    "    # save regression info (parameters, etc) in results_skl\n",
    "    results_skl = toyregr.fit(x_train, y_train)\n",
    "\n",
    "    # pull the beta parameters out from results\n",
    "    beta0_skl = toyregr.intercept_[0]\n",
    "    beta1_skl = toyregr.coef_[0][0]\n",
    "\n",
    "    print(f\"The regression coefficients from the sklearn package are: beta_0 = {beta0_skl} and beta_1 = {beta1_skl}\".format(beta0_skl, beta1_skl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_regression(k, x_train, y_train,x_test,y_test):    \n",
    "    knnreg = KNeighborsRegressor(n_neighbors=k)\n",
    "    # Fit the regressor - make sure your numpy arrays are the right shape!\n",
    "    knnreg.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the outcome on the train set using R^2\n",
    "    r2_train = knnreg.score(x_train, y_train)\n",
    "\n",
    "    # Print results\n",
    "    print(f'kNN model with {k} neighbors gives R^2 on the train set: {r2_train}')\n",
    "    knnreg.predict(x_test)\n",
    "    r2_test = knnreg.score(x_test, y_test)\n",
    "    print(f'kNN model with {k} neighbors gives R^2 on the test set: {r2_test:.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_regression(data):\n",
    "    train_data, test_data = train_test_split(data, test_size = 0.2, stratify=data['region'])\n",
    "    x_matrix = sm.add_constant(x_matrix)\n",
    "    train_transformed = build_football_data(train_data)\n",
    "    test_transformed = build_football_data(test_data)\n",
    "\n",
    "    fitted_model_1 = OLS(endog= y_train, exog=train_transformed, hasconst=True).fit()\n",
    "    fitted_model_1.summary()\n",
    "\n",
    "    # CODE TO RUN r2_score(), then answer the above question about the overall goodness of the model\n",
    "    r2_score(y_test, fitted_model_1.predict(test_transformed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc0f8570546888f8ce8bc6d01ace0f5b2aad11864bda16830580d8b55f2ba491"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
