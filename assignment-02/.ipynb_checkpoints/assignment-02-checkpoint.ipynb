{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-1316 Introduction to *Urban* Data Science \n",
    "\n",
    "\n",
    "## Assignment 2: Geographic Visualisation\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``Instructions``\n",
    "\n",
    "This assignment puts together what you learned in **Weeks 4-5**. Assignment 3 will build upon what you do in Assignment 2. \n",
    "\n",
    "_Note:_ Go through **labs and homeworks 03-04** before starting this assignment.\n",
    "\n",
    "#### 1.1 Submission\n",
    "\n",
    "Please submit the results by Brightspace under **Assignment 02**, using a single file as example,\n",
    "\n",
    "```text\n",
    "firstname_secondname_thirdname_lastname_02.html\n",
    "\n",
    "```\n",
    "\n",
    "**If your file is not named in lowercase letters as mentioned above, your assignment will not be read by the script that works to compile 200 assignments and you will miss out on the grades. I don't want that, so be exceptionally careful that you name it properly. Don't worry if you spelled your name incorrectly. I want to avoid a situation where I have 200 assignments all called assignment_02.html**\n",
    "\n",
    "Please **do not** submit any data or files other than the ``html file``.\n",
    "\n",
    "Don't worry about your submission _rendering without the images_ **after** you submitted the file on brightspace. That is a brigthspace related issue of viewing your own submission but when I download all assignments as a batch file, I get all your images and code as you intended to submit. So make sure that your html shows everything you want us to see **before you submit**. \n",
    "\n",
    "#### 1.2 How do you convert to HTML? \n",
    "\n",
    "There are 2 ways, \n",
    "\n",
    "1. from a running notebook, you can convert it into html by clicking on the file tab on the main menu of Jupyter Lab \n",
    "    * File &rightarrow; Export Notebooks as... &rightarrow; Export Notebook to HTML\n",
    "2. go to terminal or command line and type\n",
    "    * ``jupyter nbconvert --to html <notebook_name>.ipynb  ``\n",
    "\n",
    "#### 1.3 Learning Objectives\n",
    "\n",
    "This assignment is designed to support three different learning objectives. After completing the following exercises you will be able to:\n",
    "\n",
    "* Combine different datasets\n",
    "* Explore and Visualise Geographic data\n",
    "* Plot (graphs, scatter plots, choropleth, etc..) and discuss (observations, outliers or relationships) important information about the data using the `principles of graphical excellence` and `guidelines of exploratory data analysis`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Problem``\n",
    "\n",
    "`Problem Statement`: \n",
    "- For this assignment you will use two **different** datasets of The Hague, The Netherlands to formulate a hypothesis/RQ. \n",
    "- To formulate the hypothesis, provide at least `two measurements` that may be related to each other (for example: your hypothesis is that neighbourhoods with `no green space` are more prone to populations with `mental health issues`). \n",
    "- Be explicit about how you define these measurements using markdown cells (for example: how do you measure the amount of green space, and how do you measure the levels of mental health issues in the population?).\n",
    "- Observe that the measurements have a normative value attached to it (for example: according to your hypothesis, `high levels` of crime in a neighbourhood is of `more` interest). Please no not assume that there is only one normative definition of a certain measurement and skip your reasoning.\n",
    "- On the basis of the hypothesis and its associated measurements, you will conduct some exploratory/spatial data analysis and provide a list of **five neighbourhoods** in The Hague, The Netherlands characterised as areas of interest. \n",
    "\n",
    "_Note:_ I am not looking for mathematical equations as justification, but you are welcome to also form simple relations and show them in markdown. \n",
    "\n",
    "A successful student example from last year,\n",
    "\n",
    "\n",
    "> I hypothesise that neighbourhoods of The Hague with higher average incomes and less income inequality are likely to have [fewer reported crimes](https://www.npr.org/2019/04/19/715145723/why-no-one-feels-rich-the-psychology-of-inequality), due to lower levels of socioeconomic disadvantage.\n",
    "\n",
    ">Definitions of metrics:\n",
    ">- Average income (average gross personal income per resident, euros)\n",
    ">- Inequality (determined in this analysis based on the percentage of households in a neighbourhood with average income - higher percentage of average income = less inequality). This is arguably an oversimplification of the concept of inequality but is considered a suitable approximation given the available datasets.\n",
    ">- Reported crime - all offences 2019 (this is normalised in terms of population. Note this results in some anomalous values for neighbourhoods with very low populations (e.g. industrial estates or parks), some of which have been removed\n",
    ">- Population - population of each neighbourhood - used to adjust the crime statistics for population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Data``\n",
    "\n",
    "As part of the assignment files, I have provided you with the **first dataset**: the shapefiles of The Hague. After you unzip the data, we’ll work with the files of the form ``neighborhoods.xxx``, in all the different geographic formats. Put the data in a convenient location on your computer or laptop, ideally in a folder called **data** which is next to this **jupyter notebook**. I recommend taking a look at the file with format `.json` in a text editor like _atom_ for any system or notepad++ for windows. These will also make your life easy for everything else on your computer. Make sure you’ve set your working directory in the [correct manner](https://www.delftstack.com/howto/python/relative-path-in-python/).\n",
    "\n",
    "It’s a big file and it may take a while to load onto your laptop and into Python (running on the jupyter labs environment). \n",
    "\n",
    "As mentioned above in the problem introduction, you will use at least two datasets.\n",
    "\n",
    "1. **First Dataset:** Download Shapefiles provided with the assignment\n",
    "2. **Second Dataset:** Get a second dataset of your choice from The Hague city region using the links below (curate them as you like)\n",
    "\n",
    "#### More Data Sources\n",
    "\n",
    "You can find more data sources on Cities and Population, Climate indicators and Land-use in the following links.\n",
    "\n",
    "Mikhail Sirenko has prepared the **first dataset** shapefiles with love and care so that you can connect it with either [Den Haag Cijfers](https://denhaag.incijfers.nl/jive) or [CBS](https://www.cbs.nl/nl-nl/reeksen/kerncijfers-wijken-en-buurten-2004-2020) datasets without having to clean any data. For the rest of the datasets, you may need to clean up.\n",
    "\n",
    "_Note:_ Data from CBS is only complete upto 2017. You will have to subset the data on municpality using the variable name `gm_naam = 's-Gravenhage` and then subset on neighbourhood resolution using variable name `recs = Buurt` to get the data that can match the shapefiles we have provided. \n",
    "\n",
    "* https://denhaag.incijfers.nl/jive (available in English on the website)\n",
    "* https://www.cbs.nl/nl-nl/reeksen/kerncijfers-wijken-en-buurten-2004-2020\n",
    "* http://citypopulation.de/ \n",
    "* https://www.census.gov/programs-surveys/geography.html \n",
    "* https://www.eea.europa.eu/data-and-maps \n",
    "* http://download.geofabrik.de/\n",
    "\n",
    "#### In case you get more data as shapefiles, and want to play with projections, a nice guide for it is [here](https://automating-gis-processes.github.io/CSC18/lessons/L2/projections.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Tasks``\n",
    "\n",
    "For your convenience, the assignment has been divided into the following tasks, \n",
    "\n",
    "1. Use two datasets: merge 1 shapefile (already provided) and a csv file (you find and obtain)\n",
    "2. Formulate a hypothesis and the measurements you are going to use\n",
    "3. Clean your data and make it tabular for your own good! (think about weeks 1-2 and assignment 1)\n",
    "4. Carry out an exploratory data analysis (EDA)\n",
    "4. Report and justify your choice of the list of 5 neighbourhoods on the basis of your analysis.\n",
    "    * Use at least **3 figures** to support your analysis. Think about exploratory data analysis (build data, clean data, explore global/group properties). \n",
    "    * These figures should have followed the principles of graphical excellence. Using markdown, write explicity under each figure at least **3 principles of excellence** you have used to make it.\n",
    "    * Create **choropleths** to display region-specific information (ex. population, voting choice or jobs availability) together with some other elements like the sea, canals, centroids, or amenities (you may try Open Street Maps data - using `osmnx`).\n",
    "    * Be careful with the use of color (and try to be inclusive of color blind people)\n",
    "    * Use **one method** from the lectures to discuss what you observe for your variable(s). Examples below,\n",
    "          * local or global spatial autocorrelation\n",
    "          * network measures\n",
    "          * spatial weights / spatial lag\n",
    "          * binning\n",
    "          * feature scaling, normalisation or standardisation\n",
    "\n",
    "***Remember to always document your code! Justify everything you do (cleaning data, analysisng data, exploring data, defining hypothesis or measurements, etc.) using markdown cells as you go through the notebook.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Start your analysis``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
