{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-1316 Introduction to *Urban* Data Science \n",
    "\n",
    "\n",
    "## Homework 2: Data Engineering and Transformation\n",
    "\n",
    "**TU Delft**<br>\n",
    "**Q1 2022**<br>\n",
    "**Instructor:** Trivik Verma <br>\n",
    "**TAs:** Auriane Técourt, Dorukhan Yeşilli, Ludovica Bindi, Nicolò Canal, Ruth Nelson, Vaibhavi Srivastava <br>\n",
    "**[Centre for Urban Science & Policy]( https://cusp.tbm.tudelft.nl/)** <br>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This homework assignment document will guide you through five tasks in cleaning your data.__\n",
    "\n",
    "1. Reading and Summarizing the Data.\n",
    "2. Subsetting the Data.\n",
    "3. Manage Missing Data.\n",
    "4. Shape the Data.\n",
    "5. Saving the Results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Loading the data:\n",
    "\n",
    "- Load the `goodreads.csv` file into Python\n",
    "- Explore it by looking at first and last 5 rows\n",
    "- Change the column names to `[\"rating\", 'review_count', 'isbn', 'booktype','author_url', 'year', 'genre_urls', 'dir','rating_count', 'name']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5999 entries, 0 to 5998\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   rating        5997 non-null   float64\n",
      " 1   review_count  5999 non-null   object \n",
      " 2   isbn          5524 non-null   object \n",
      " 3   booktype      5999 non-null   object \n",
      " 4   author_url    5999 non-null   object \n",
      " 5   year          5992 non-null   float64\n",
      " 6   genre_urls    5937 non-null   object \n",
      " 7   dir           5999 non-null   object \n",
      " 8   rating_count  5999 non-null   object \n",
      " 9   name          5999 non-null   object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 468.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n",
    "data_source = pd.read_csv('data/goodreads.csv')\n",
    "data_source.columns = [\"rating\", 'review_count', 'isbn', 'booktype','author_url', 'year', 'genre_urls', 'dir','rating_count', 'name']\n",
    "#print(data_source.info())\n",
    "#data_source = data_source.fillna(0)\n",
    "#data_source = data_source.replace(0)\n",
    "print(data_source.info())\n",
    "#data_source['review_count'] = data_source['review_count'].astype(int)\n",
    "#data_source['rating_count'] = data_source['rating_count'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Subsetting the data\n",
    "\n",
    "- Subset the data by creating new dataframe only with `[\"rating\", 'isbn', 'author_url', 'year', 'genre_urls', 'name']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rating', 'isbn', 'author_url', 'year', 'genre_urls', 'name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n",
    "reviews_subset = data_source.loc[:,[\"rating\", 'isbn', 'author_url', 'year', 'genre_urls', 'name']]\n",
    "print(reviews_subset.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Manage Missing Data\n",
    "We’ve got a number of ways in general of dealing with missing data. These involve\n",
    "\n",
    "1. Dropping off cases (or rows) in the data with any missing variables\n",
    "2. Excluding variables in the data with any missing data \n",
    "3. Selectively choosing indicators with only a limited amount of missing data\n",
    "4. Replacing missing variables with averages, or other representative values\n",
    "5. Creating a separate model to predict missing data\n",
    "\n",
    "- Count the missing values in each column\n",
    "- Manage the missing values (delete or replace values or leave them as they are) and briefly explain your choice for each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5495 entries, 0 to 5998\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   rating      5495 non-null   float64\n",
      " 1   isbn        5495 non-null   object \n",
      " 2   author_url  5495 non-null   object \n",
      " 3   year        5495 non-null   float64\n",
      " 4   genre_urls  5495 non-null   object \n",
      " 5   name        5495 non-null   object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 300.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n",
    "print(reviews_subset.info())\n",
    "#drop rows based on Infos gathered in info() method\n",
    "reviews_subset = reviews_subset.drop(reviews_subset[pd.isnull(reviews_subset.rating)].index)\n",
    "reviews_subset = reviews_subset.drop(reviews_subset[pd.isnull(reviews_subset.isbn)|pd.isna(reviews_subset.isbn)].index)\n",
    "reviews_subset = reviews_subset.drop(reviews_subset[pd.isnull(reviews_subset.year)|pd.isna(reviews_subset.year)].index)\n",
    "reviews_subset = reviews_subset.drop(reviews_subset[pd.isnull(reviews_subset.genre_urls)|pd.isna(reviews_subset.genre_urls)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Shape the data\n",
    "- Parse the `author_url` to create new column named `author`\n",
    "- Sort the data by putting higher rates go first. If there are overlapping rates, try to put earlier years go first.\n",
    "- **(Stretch Goal)** Examine how many books were published at each year and find lowest, highest rate of each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 author  rating    year\n",
      "3711        Chris Lange    4.93  2013.0\n",
      "910         Omar Farhad    4.85  2014.0\n",
      "2629       Joe Connolly    4.80  2012.0\n",
      "5656           Joe Egly    4.80  2012.0\n",
      "248      Bill Watterson    4.80  2005.0\n",
      "5873    Odysseus Elytis    4.78  1972.0\n",
      "5448  Cindy Springsteen    4.77  2012.0\n",
      "1594  Brandon Sanderson    4.76  2014.0\n",
      "1852          Anonymous    4.76  2007.0\n",
      "4083        Neil Gaiman    4.75  2008.0\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n",
    "reviews_subset['author'] = reviews_subset.author_url.map(lambda url: url.split('/')[-1].split('.')[1].replace('_',' '))\n",
    "reviews_subset = reviews_subset.sort_values(by=[\"rating\",\"year\"],ascending=False)\n",
    "print(reviews_subset.loc[:,['author','rating','year']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Books published per year </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Saving the results\n",
    "- Save the cleaned dataframe as 'hw-03-cleaned.csv' in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
