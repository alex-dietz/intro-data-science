{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-1316 Introduction to *Urban* Data Science \n",
    "\n",
    "\n",
    "## Assignment 1: Data Collection and Wrangling\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``Instructions``\n",
    "\n",
    "This assignment puts together what you learned in **Weeks 1-2**. You will be working with a dataset which is in the form of a spreadsheet. It may contain many different data types in the columns. All data frames contain column names, which are strings, and row indices, which are integers. In this assignment you will illustrate your knwoledge about bundling various kinds of data together to be able to do higher-level tasks.\n",
    "\n",
    "_Note:_ Go through **labs and homeworks 00-02** before starting this assignment. \n",
    "\n",
    "#### 1.1 Submission\n",
    "\n",
    "Please submit the results by Brightspace under **Assignment 01**, using a single file as example,\n",
    "\n",
    "```text\n",
    "firstname_secondname_thirdname_lastname_01.html\n",
    "\n",
    "```\n",
    "\n",
    "**If your file is not named in lowercase letters as mentioned above, your assignment will not be read by the script that works to compile > 200 assignments and you will miss out on the grades. I don't want that, so be exceptionally careful that you name it properly. Don't worry if you spelled your name incorrectly. I want to avoid a situation where I have 200 assignments all called assignment_01.html**\n",
    "\n",
    "Please **do not** submit any data or files other than the ``html file``.\n",
    "\n",
    "#### 1.2 How do you convert to HTML? \n",
    "\n",
    "There are 2 ways, \n",
    "\n",
    "1. from a running notebook, you can convert it into html by clicking on the file tab on the main menu of Jupyter Lab \n",
    "    * File &rightarrow; Export Notebooks as... &rightarrow; Export Notebook to HTML\n",
    "2. go to terminal or command line and type\n",
    "    * ``jupyter nbconvert --to html <notebook_name>.ipynb  ``\n",
    "\n",
    "\n",
    "#### 1.3 Learning Objectives\n",
    "\n",
    "This assignment is designed to support three different learning objectives. After completing the following exercises you will be able to:\n",
    "\n",
    "* Explore variables in a dataset\n",
    "* Manage missing data \n",
    "* Reshape data to get it in a form useful for statistical analysis \n",
    "\n",
    "#### 1.4 Tasks\n",
    "\n",
    "This assignment requires you to go through five tasks in cleaning your data. \n",
    "\n",
    "1. Reading and Summarizing the Data.\n",
    "2. Subsetting the Data. This extracts just the part of the data you want to analyse. \n",
    "3. Manage Missing Data. Some data is not available for all objects of interest (rows) or all variables for every object (columns). \n",
    "4. Shape the Data. We need to convert the data into a suitable format for analysis. \n",
    "5. Saving the Results. The results are saved for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Task 1: Downloading the Data``\n",
    "\n",
    "For this assignment we are going to use the World Development Indicators database as a source of data. The World Development Indicators is the primary data source for the World Bank, a financial institution that provides loans to developing nations for investment in national infrastructure. The database is comprised of data from officially recognized sources all over the world. The data consists of time series which in some cases dates back over fifty years. Nations are variously categorized into different groups in order to permit the comparative analysis of nations. \n",
    "\n",
    "You can download the data here as a csv file (It is intentional that I am not explicitly telling you where exactly you will find the csv file on this website):\n",
    "http://data.worldbank.org/data-catalog/world-development-indicators\n",
    "\n",
    "So after you unzip, we’ll work with the file ``WDIData.csv``, which is in a modified csv format. All the other files around it are informative and may be useful for you to do a better analyses. These extra files only provide more information on data sources of indicators used in the main file. Put the data in a convenient location on your computer or laptop, ideally in a folder called **data** which is next to this **jupyter notebook**. I recommend taking a look at the file in a text editor like _atom_ for any system or notepad++ for windows. These will also make your life easy for everything else on your computer. \n",
    "\n",
    "It’s a big file and it may take a while to load onto your laptop and into Python (running on the jupyter labs environment). \n",
    "\n",
    "The data is organized with one country and all the data for one indicator on each line. But there are many countries, and many indicators. Every indicator may have data reaching back from _1960_. These are all shown together on the same line. Because the data is replicated by country, the file is longer than it is wide. We call it “long” data. Thus, each country may be repeated on rows based on the indicator that is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise: Downloading the Data``\n",
    "\n",
    "**IMPORTANT** make sure your code can run independent of the machine. i.e. \n",
    "- Use relative path links instead of absolute paths. If your data folder is named C:/HelloKitty/MyGummyBears/IlovePython/WDIData.csv, then your program will not be reproducible on any other machine. Check out this very easy to follow and handy guide on [relative paths](https://www.delftstack.com/howto/python/relative-path-in-python/).\n",
    "- Organise the data in a folder called `data` and run your notebook next to it organised as follows\n",
    "\n",
    "```text\n",
    "├── trivik_verma_01.ipynb\n",
    "├── data\n",
    "│   ├── WDIData.csv\n",
    "```\n",
    "\n",
    "- Load the `WDIData.csv` file into Python\n",
    "- Explore it by looking at first and last 5 rows\n",
    "- Programattically find and print information on the data,\n",
    "    - number of columns in the data\n",
    "    - names of the columns in the data \n",
    "    - number of rows in the data (excluding the header names)\n",
    "    - how many unique regions/countries in the data\n",
    "    - how many unique national indicators are in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Import of necessary libraries and data </h1>\n",
    "    <br>\n",
    "    I import pandas, an open source library for data science, to analyze the data. As a next step, I use the read_csv function from pandas to read the data from the csv file. The data is obtained from the World Bank and contains information on the development of countries measured by different indicators and over time, starting as early as 1960. The csv file is saved in a data folder to make this notebook reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas package and call it pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use panda's read_csv function to read the csv file and save it in wdi_data, which is a dataframe object\n",
    "wdi_data = pd.read_csv('data/WDIData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Explore the data</h1>\n",
    "<br>\n",
    "I want to get an overview of the data to get a better understanding of the structure. I use the following pandas functions to do so:\n",
    "\n",
    " - head() --> provides the first five entries of the dataframe\n",
    " - tail() --> provides the last five entries of the dataframe\n",
    " - columns --> provides the name of all columns\n",
    " - shape --> provides the number of rows and columns of the dataframe\n",
    " - unique() --> provides the number of unique values in a column of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Country Name Country Code  \\\n",
      "0  Africa Eastern and Southern          AFE   \n",
      "1  Africa Eastern and Southern          AFE   \n",
      "2  Africa Eastern and Southern          AFE   \n",
      "3  Africa Eastern and Southern          AFE   \n",
      "4  Africa Eastern and Southern          AFE   \n",
      "\n",
      "                                      Indicator Name     Indicator Code  1960  \\\n",
      "0  Access to clean fuels and technologies for coo...     EG.CFT.ACCS.ZS   NaN   \n",
      "1  Access to clean fuels and technologies for coo...  EG.CFT.ACCS.RU.ZS   NaN   \n",
      "2  Access to clean fuels and technologies for coo...  EG.CFT.ACCS.UR.ZS   NaN   \n",
      "3            Access to electricity (% of population)     EG.ELC.ACCS.ZS   NaN   \n",
      "4  Access to electricity, rural (% of rural popul...  EG.ELC.ACCS.RU.ZS   NaN   \n",
      "\n",
      "   1961  1962  1963  1964  1965  ...       2013       2014       2015  \\\n",
      "0   NaN   NaN   NaN   NaN   NaN  ...  16.936004  17.337896  17.687093   \n",
      "1   NaN   NaN   NaN   NaN   NaN  ...   6.499471   6.680066   6.859110   \n",
      "2   NaN   NaN   NaN   NaN   NaN  ...  37.855399  38.046781  38.326255   \n",
      "3   NaN   NaN   NaN   NaN   NaN  ...  31.794160  32.001027  33.871910   \n",
      "4   NaN   NaN   NaN   NaN   NaN  ...  18.663502  17.633986  16.464681   \n",
      "\n",
      "        2016       2017       2018       2019       2020  2021  Unnamed: 66  \n",
      "0  18.140971  18.491344  18.825520  19.272212  19.628009   NaN          NaN  \n",
      "1   7.016238   7.180364   7.322294   7.517191   7.651598   NaN          NaN  \n",
      "2  38.468426  38.670044  38.722783  38.927016  39.042839   NaN          NaN  \n",
      "3  38.880173  40.261358  43.061877  44.270860  45.803485   NaN          NaN  \n",
      "4  24.531436  25.345111  27.449908  29.641760  30.404935   NaN          NaN  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "#print the first five entries\n",
    "print(wdi_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country Name Country Code  \\\n",
      "383567     Zimbabwe          ZWE   \n",
      "383568     Zimbabwe          ZWE   \n",
      "383569     Zimbabwe          ZWE   \n",
      "383570     Zimbabwe          ZWE   \n",
      "383571     Zimbabwe          ZWE   \n",
      "\n",
      "                                           Indicator Name     Indicator Code  \\\n",
      "383567  Women who believe a husband is justified in be...     SG.VAW.REFU.ZS   \n",
      "383568  Women who were first married by age 15 (% of w...  SP.M15.2024.FE.ZS   \n",
      "383569  Women who were first married by age 18 (% of w...  SP.M18.2024.FE.ZS   \n",
      "383570  Women's share of population ages 15+ living wi...  SH.DYN.AIDS.FE.ZS   \n",
      "383571  Young people (ages 15-24) newly infected with HIV     SH.HIV.INCD.YG   \n",
      "\n",
      "        1960  1961  1962  1963  1964  1965  ...     2013     2014     2015  \\\n",
      "383567   NaN   NaN   NaN   NaN   NaN   NaN  ...      NaN      NaN     14.5   \n",
      "383568   NaN   NaN   NaN   NaN   NaN   NaN  ...      NaN      NaN      3.7   \n",
      "383569   NaN   NaN   NaN   NaN   NaN   NaN  ...      NaN     33.5     32.4   \n",
      "383570   NaN   NaN   NaN   NaN   NaN   NaN  ...     59.2     59.4     59.5   \n",
      "383571   NaN   NaN   NaN   NaN   NaN   NaN  ...  18000.0  17000.0  15000.0   \n",
      "\n",
      "           2016     2017    2018         2019    2020  2021  Unnamed: 66  \n",
      "383567      NaN      NaN     NaN          NaN     NaN   NaN          NaN  \n",
      "383568      NaN      NaN     NaN     5.418352     NaN   NaN          NaN  \n",
      "383569      NaN      NaN     NaN    33.658057     NaN   NaN          NaN  \n",
      "383570     59.7     59.9    60.0    60.200000    60.4   NaN          NaN  \n",
      "383571  14000.0  12000.0  9700.0  9600.000000  7500.0   NaN          NaN  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "#print the last five entries\n",
    "print(wdi_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first structural analysis showed me that I have 67 columns, as the years are on the columns while to country indicator combination describes each row. Furthermore, I already see some missing values in the data. Moreover, it is also clear that the data does not only include countries but also regions, as the first entries are for the region \"Africa Eastern and Southern\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021',\n",
      "       'Unnamed: 66'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print the names of the columns to get a better understanding\n",
    "print(wdi_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output showed me that data was collected from 1960 to 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "# print the number of columns by using the python function len()\n",
    "print(len(wdi_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383572\n"
     ]
    }
   ],
   "source": [
    "# To fully see the length of the dataframe, I print the number of rows\n",
    "print(wdi_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n"
     ]
    }
   ],
   "source": [
    "# identify the number of unique countries\n",
    "print(len(wdi_data['Country Code'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442\n"
     ]
    }
   ],
   "source": [
    "#identify the number of unique indicators\n",
    "print(len(wdi_data['Indicator Code'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collected the following information:\n",
    "- number of columns in the data: 67\n",
    "- number of rows in the data: 383572\n",
    "- number of unique countries/regions 266\n",
    "- number of unique indicators  1442 <br>\n",
    "\n",
    "I notice that they are way more rows than columns. Together with the information I got on the names of the columns, I can conclude that the data is in a long format. This means that each row contains information on one country and one indicator. The data is not in a wide format, where each row contains information on one country and all indicators. This is important to know, because I might have to reshape the data later on. Hence, I want to know how many unique countries and indicators are in the data. I use the unique() function to get this information. I notice that there are 266 unique countries/regions and 1442 unique indicators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Task 2: Subsetting the Data``\n",
    "\n",
    "From now on we want a much smaller subset of this data. We have all the valid country information using the country code information in ``WDICountry.csv`` or in one of the columns of the main data itself. (Note that it is best practice to search using country codes and not real country names. Countries are known by many names by many different people and languages.) In the future, World Bank may change the datasets with new country names as the data collection efforts of orgs is not relevant to geopolitics. Hence, it is important to work with codes as opposed to names to make our analyses more reproducible across time.\n",
    "\n",
    "The file ``WDISeries.csv`` contains a description of all the indicator variables and their names. We won’t actually use this file in the analysis, but you will find it helpful in designing your own analysis. Your objectives for this assignment is to select **4-7 variables** for further exploratory statistics (more information later in exercises). \n",
    "\n",
    "For example, I can show you what I did, \n",
    "\n",
    "```text\n",
    "My hypothesis\n",
    "I’d like to examine world broadband access. For that reason I chose a broadband account variable. The data is organized by country. I want to control for the wealth, population, and land area of the country. I also have a hypothesis that more urban countries are more likely to have good broadband services. There are economies of scale when providing services to a large city. \n",
    "\n",
    "I hypothesize that larger countries have lesser access, since it is expensive to provide access over larger areas. On the contrary, countries with a lot of urban land area can take advantage of economies of scale resulting in relatively more broadband users concentrated in smaller zones within the country. We also hypothesize that wealthier countries have better broadband access, since there is a larger market to provide the newest services. A final variable which we add is rail lines. I hypothesize that broadband lines can take advantage of existing infrastructure right-of-ways, of which rail is a surrogate measure. Furthermore, the presence of rail lines may indicate other factors including a geography which is conclusive to physical development, and favourable institutional factors which promote high technology development. \n",
    "\n",
    "My choice of variables were, \n",
    "\n",
    "| Variable Name                 | Variable Code     |\n",
    "| ----------------------------- | ----------------- |\n",
    "| Fixed broadband subscriptions | IT.NET.BBND       |\n",
    "| GDP (current US$)             | NY.GDP.MKTP.CD    |\n",
    "| Population, total             | SP.POP.TOTL       |\n",
    "| Land area (sq. km)            | AG.LND.TOTL.K2    |\n",
    "| Urban land area (sq. km)      | AG.LND.TOTL.UR.K2 |\n",
    "| Rail lines (total route-km)   | IS.RRS.TOTL.KM    |\n",
    "\n",
    "```\n",
    "\n",
    "Recall that the data is organized with countries and variables on the rows, and years on the column. Using this table as a guide, I can now extract only those rows which contain these variable names, and throw out the great many other variables that I will not need. You are expected to do the same further down in the exercise. \n",
    "\n",
    "For now let’s set aside the added complexity of time series and dynamics. Our task is to select just one year with a lot of data for most countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise: Subsetting the Data``\n",
    "\n",
    "- state your hypothesis in a markdown cell as I showed in the example above (there is no single right hypothesis, you are free to make a **reasonable** choice for this task)\n",
    "- find the variables of interest for your hypothesis and mention them in the markdown cell (4-7 variables)\n",
    "- your dataframe would have greatly reduced in size and looks neater, show us what it looks like now using head() or something similar\n",
    "    - show some statistics like number or rows, columns, names of variables and unique countries etc.\n",
    "- you’ll see that your data contains values for many years of data, or perhaps NA (“not applicable”), if the country has failed to report its findings. \n",
    "- For now let’s set aside the added complexity of time series and dynamics. Our task is to select just one year with a lot of data for most countries.\n",
    "    - choose one year/column that you want to work with and drop the rest of the years. \n",
    "\n",
    "You can count the columns manually, but in a large data set like this it is accurate and convenient to let python calculate this for us. Get the index of relevant columns and store them in a variable. \n",
    "\n",
    "- when you do this for your own variables, you also will want to experiment to see which year you want to use. You might also choose to drop off some of your initial variable choices if they are poorly collected. \n",
    "- subset the data by creating a new dataframe only with ``your variables`` `[v1, v2, v3...]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>My hypothesis</h3>\n",
    "\n",
    "I like to analyze the a population health index. Therefore, I choose life expectancy as a proxy as life expectancy provides me with the mortality over a lifespan and is recorded for a large number of countries and regions.\n",
    "I hypothesize that richer countries have a higher life expectancy as they have more resources and better infrastructure to provide health services. Hence, I include the country's wealth as a variable. I look at the UHC service coverage index, which states a score from 0 to 100 for essential health services (based on tracer interventions that include reproductive, maternal, newborn and child health, infectious diseases, noncommunicable diseases and service capacity and access). THe higher the score the higher is the coverage for essential health services. Furthermore, I argue that countries with a higher disparity between incomes, have a lower life expectancy as the country might have a high level of wealth, yet it is focused on a few while the larger part of the population will have a lower coverage. Hence, I include the Gini index as a variable, as it measures the distribution of income, 0 meaning perfect equality and 100 perfect inequality.\n",
    " I also hypothesize that countries with a higher urban population have a higher coverage as they have better infrastructure and more resources. Hence, I include the urban population as a variable. I also hypothesize that countries with a higher literacy rate have a higher coverage as they are more educated and hence have a better understanding of the importance of health services. Hence, I include the literacy rate as a variable. \n",
    " I also look at the coverage of social insurance programs, as I argue that a higher coverage will lead to a higher life expectancy due to the fact, that more people will have access to health services and can also afford necessary but expensive treatments.\n",
    "My choice of variables were, \n",
    "<br>\n",
    "\n",
    "| Variable Name                                             | Variable Code     |\n",
    "| -----------------------------                             | ----------------- |\n",
    "| life expectancy                                           | SP.DYN.LE00.IN    |\n",
    "| UHC service coverage index                                | SH.UHC.SRVS.CV.XD       |\n",
    "| GDP (current US$)                                         | NY.GDP.MKTP.CD    |\n",
    "| Gini coefficent                                           | SI.POV.GINI     |\n",
    "| Coverage of social insurance programs (%)                 | per_si_allsi.cov_pop_tot |\n",
    "|Literacy rate, adult total (% of people ages 15 and above) | SE.ADT.LITR.ZS |\n",
    "| Hospital Beds (Per 1,000 People)                          | SH.MED.BEDS.ZS    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating the subset</h3>\n",
    "\n",
    "To obtain my subset of the original dataset, I use a python list that contains the codes for the selected indicators. I choose the indicator codes as the World Bank might change the names of the indicators over time.\n",
    "Afterwards, I use this list of indicator codes together with pandas isin() function to create a subset which I save in the variable wdi_data_subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of selected indicators\n",
    "selected_variables = ['SP.DYN.LE00.IN','SH.UHC.SRVS.CV.XD','NY.GDP.MKTP.CD','SI.POV.GINI','per_si_allsi.cov_pop_tot','SE.ADT.LITR.ZS','SH.MED.BEDS.ZS']\n",
    "#subset of the dataframe with only the selected indicators\n",
    "wdi_data_subset = wdi_data[wdi_data['Indicator Code'].isin(selected_variables)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Overview on subset</h3>\n",
    "\n",
    "To quickly check if the subset was created correctly, I use the head() function to display the first 5 rows of the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Country Name Country Code  \\\n",
      "243  Africa Eastern and Southern          AFE   \n",
      "467  Africa Eastern and Southern          AFE   \n",
      "491  Africa Eastern and Southern          AFE   \n",
      "558  Africa Eastern and Southern          AFE   \n",
      "697  Africa Eastern and Southern          AFE   \n",
      "\n",
      "                                        Indicator Name  \\\n",
      "243  Coverage of social insurance programs (% of po...   \n",
      "467                                  GDP (current US$)   \n",
      "491                                         Gini index   \n",
      "558                   Hospital beds (per 1,000 people)   \n",
      "697            Life expectancy at birth, total (years)   \n",
      "\n",
      "               Indicator Code          1960          1961          1962  \\\n",
      "243  per_si_allsi.cov_pop_tot           NaN           NaN           NaN   \n",
      "467            NY.GDP.MKTP.CD  2.129059e+10  2.180847e+10  2.370702e+10   \n",
      "491               SI.POV.GINI           NaN           NaN           NaN   \n",
      "558            SH.MED.BEDS.ZS  1.959677e+00           NaN           NaN   \n",
      "697            SP.DYN.LE00.IN  4.271605e+01  4.316694e+01  4.360399e+01   \n",
      "\n",
      "             1963          1964          1965  ...          2013  \\\n",
      "243           NaN           NaN           NaN  ...           NaN   \n",
      "467  2.821004e+10  2.611879e+10  2.968217e+10  ...  9.839370e+11   \n",
      "491           NaN           NaN           NaN  ...           NaN   \n",
      "558           NaN           NaN           NaN  ...           NaN   \n",
      "697  4.402562e+01  4.443272e+01  4.482692e+01  ...  6.095336e+01   \n",
      "\n",
      "             2014          2015          2016          2017          2018  \\\n",
      "243           NaN           NaN           NaN           NaN           NaN   \n",
      "467  1.003679e+12  9.242525e+11  8.823551e+11  1.020647e+12  9.910223e+11   \n",
      "491           NaN           NaN           NaN           NaN           NaN   \n",
      "558           NaN           NaN           NaN           NaN           NaN   \n",
      "697  6.164737e+01  6.225929e+01  6.278768e+01  6.324626e+01  6.364899e+01   \n",
      "\n",
      "             2019          2020          2021  Unnamed: 66  \n",
      "243           NaN           NaN           NaN          NaN  \n",
      "467  9.975340e+11  9.216459e+11  1.082096e+12          NaN  \n",
      "491           NaN           NaN           NaN          NaN  \n",
      "558           NaN           NaN           NaN          NaN  \n",
      "697  6.400521e+01  6.432570e+01           NaN          NaN  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "#print the first five rows of the subset with head()\n",
    "print(wdi_data_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that the subset still contains 67 columns and also my selected indicators, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, I want to get a quick overview of the new dataframe and thus, use pandas info() function to display the number of rows and columns, the column names and the data types of the columns, as well as the non-null value count for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1862 entries, 243 to 383516\n",
      "Data columns (total 67 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Country Name    1862 non-null   object \n",
      " 1   Country Code    1862 non-null   object \n",
      " 2   Indicator Name  1862 non-null   object \n",
      " 3   Indicator Code  1862 non-null   object \n",
      " 4   1960            534 non-null    float64\n",
      " 5   1961            375 non-null    float64\n",
      " 6   1962            377 non-null    float64\n",
      " 7   1963            376 non-null    float64\n",
      " 8   1964            376 non-null    float64\n",
      " 9   1965            394 non-null    float64\n",
      " 10  1966            394 non-null    float64\n",
      " 11  1967            399 non-null    float64\n",
      " 12  1968            403 non-null    float64\n",
      " 13  1969            404 non-null    float64\n",
      " 14  1970            587 non-null    float64\n",
      " 15  1971            420 non-null    float64\n",
      " 16  1972            422 non-null    float64\n",
      " 17  1973            423 non-null    float64\n",
      " 18  1974            430 non-null    float64\n",
      " 19  1975            526 non-null    float64\n",
      " 20  1976            457 non-null    float64\n",
      " 21  1977            451 non-null    float64\n",
      " 22  1978            454 non-null    float64\n",
      " 23  1979            463 non-null    float64\n",
      " 24  1980            608 non-null    float64\n",
      " 25  1981            560 non-null    float64\n",
      " 26  1982            504 non-null    float64\n",
      " 27  1983            500 non-null    float64\n",
      " 28  1984            515 non-null    float64\n",
      " 29  1985            591 non-null    float64\n",
      " 30  1986            556 non-null    float64\n",
      " 31  1987            573 non-null    float64\n",
      " 32  1988            565 non-null    float64\n",
      " 33  1989            598 non-null    float64\n",
      " 34  1990            733 non-null    float64\n",
      " 35  1991            649 non-null    float64\n",
      " 36  1992            635 non-null    float64\n",
      " 37  1993            647 non-null    float64\n",
      " 38  1994            638 non-null    float64\n",
      " 39  1995            651 non-null    float64\n",
      " 40  1996            682 non-null    float64\n",
      " 41  1997            641 non-null    float64\n",
      " 42  1998            651 non-null    float64\n",
      " 43  1999            645 non-null    float64\n",
      " 44  2000            965 non-null    float64\n",
      " 45  2001            731 non-null    float64\n",
      " 46  2002            760 non-null    float64\n",
      " 47  2003            752 non-null    float64\n",
      " 48  2004            769 non-null    float64\n",
      " 49  2005            1021 non-null   float64\n",
      " 50  2006            835 non-null    float64\n",
      " 51  2007            820 non-null    float64\n",
      " 52  2008            825 non-null    float64\n",
      " 53  2009            844 non-null    float64\n",
      " 54  2010            1086 non-null   float64\n",
      " 55  2011            884 non-null    float64\n",
      " 56  2012            865 non-null    float64\n",
      " 57  2013            826 non-null    float64\n",
      " 58  2014            858 non-null    float64\n",
      " 59  2015            1048 non-null   float64\n",
      " 60  2016            826 non-null    float64\n",
      " 61  2017            1009 non-null   float64\n",
      " 62  2018            768 non-null    float64\n",
      " 63  2019            852 non-null    float64\n",
      " 64  2020            573 non-null    float64\n",
      " 65  2021            231 non-null    float64\n",
      " 66  Unnamed: 66     0 non-null      float64\n",
      "dtypes: float64(63), object(4)\n",
      "memory usage: 989.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wdi_data_subset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selection of specific year</h3>\n",
    "\n",
    "As this analysis will not analyze the data for each country over time, I want to select only one year. To keep the highest level of quality for my analysis, I want to find out the year with the highest number of provided values. To do so, I use the pandas count() function to count the number of non-null values for each column. I then use the idxmax() function to find the column with the highest number of non-null values. I save the result in the variable year_with_most_values. As I want to exclude the first columns that are specific to countries and regions, I use the iloc[] function and look only from the 5th column onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    }
   ],
   "source": [
    "#Year with most entries, only included year columns with iloc\n",
    "year_with_most_values = wdi_data_subset.iloc[:,5:].count().idxmax()\n",
    "print(year_with_most_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I have identified the year with the most values, in this case 2010, I want to create a new dataframe that only contains this year. To do so, I use the pandas loc[] function to select all rows and only the columns on the country, indicator, and selected year. I save the result in the variable wdi_data_subset_for_selected_year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list with columns that I will need in the new dataframe\n",
    "relevant_columns = ['Country Name','Country Code','Indicator Name','Indicator Code',year_with_most_values]\n",
    "#create new dataframe with only the relevant columns and all rows\n",
    "wdi_data_subset_for_selected_year = wdi_data_subset.loc[:,relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1862 entries, 243 to 383516\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Country Name    1862 non-null   object \n",
      " 1   Country Code    1862 non-null   object \n",
      " 2   Indicator Name  1862 non-null   object \n",
      " 3   Indicator Code  1862 non-null   object \n",
      " 4   2010            1086 non-null   float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 87.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Obtain overview on new created dataset using info()\n",
    "print(wdi_data_subset_for_selected_year.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checking Quality of Selected Indicators</h3>\n",
    "\n",
    "As a next step, I want to check the quality of each indicator for the selected year. I do so by counting the values for the selected year, in this case 2010. To do so, I use pandas groupby() function to group the dataframe by the indicator code and then use the count() function to count the number of non-null values for each indicator. I print the result to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             Country Name  \\\n",
      "Indicator Code           Indicator Name                                                     \n",
      "NY.GDP.MKTP.CD           GDP (current US$)                                            266   \n",
      "SE.ADT.LITR.ZS           Literacy rate, adult total (% of people ages 15...           266   \n",
      "SH.MED.BEDS.ZS           Hospital beds (per 1,000 people)                             266   \n",
      "SH.UHC.SRVS.CV.XD        UHC service coverage index                                   266   \n",
      "SI.POV.GINI              Gini index                                                   266   \n",
      "SP.DYN.LE00.IN           Life expectancy at birth, total (years)                      266   \n",
      "per_si_allsi.cov_pop_tot Coverage of social insurance programs (% of pop...           266   \n",
      "\n",
      "                                                                             Country Code  \\\n",
      "Indicator Code           Indicator Name                                                     \n",
      "NY.GDP.MKTP.CD           GDP (current US$)                                            266   \n",
      "SE.ADT.LITR.ZS           Literacy rate, adult total (% of people ages 15...           266   \n",
      "SH.MED.BEDS.ZS           Hospital beds (per 1,000 people)                             266   \n",
      "SH.UHC.SRVS.CV.XD        UHC service coverage index                                   266   \n",
      "SI.POV.GINI              Gini index                                                   266   \n",
      "SP.DYN.LE00.IN           Life expectancy at birth, total (years)                      266   \n",
      "per_si_allsi.cov_pop_tot Coverage of social insurance programs (% of pop...           266   \n",
      "\n",
      "                                                                             2010  \n",
      "Indicator Code           Indicator Name                                            \n",
      "NY.GDP.MKTP.CD           GDP (current US$)                                    256  \n",
      "SE.ADT.LITR.ZS           Literacy rate, adult total (% of people ages 15...    91  \n",
      "SH.MED.BEDS.ZS           Hospital beds (per 1,000 people)                     171  \n",
      "SH.UHC.SRVS.CV.XD        UHC service coverage index                           204  \n",
      "SI.POV.GINI              Gini index                                            84  \n",
      "SP.DYN.LE00.IN           Life expectancy at birth, total (years)              248  \n",
      "per_si_allsi.cov_pop_tot Coverage of social insurance programs (% of pop...    32  \n"
     ]
    }
   ],
   "source": [
    "# display count of values for each indicator\n",
    "print(wdi_data_subset_for_selected_year.groupby(['Indicator Code','Indicator Name']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Task 4: Reshape the Data``\n",
    "\n",
    "As you may have noticed from your outputs above, the data is still not  in a form which is suitable for statistical analysis. Every row is a a combination of a country, a few variables, and a year. We’d like each row instead to be a country, and for there to be many columns according to the variables involved. \n",
    "\n",
    "The data is stored with one country and one variable by year. That’s long data. We want to convert it so each row is a case, and that case is a country. Then each column can store the variables for that country. That’s wide data. Our objectives in this section is to convert from one format of the data to the other. For the purposes of this assignment we’re not going to handle time series data, even though the World Development Indicators data often has many years of time history collected for each of the nations. That's why I asked you to select a particular year only.\n",
    "\n",
    "You might ask why the original data was even stored in this manner. The most efficient means of storing data is to store everything once and then not repeat it. So for instance each element of this data set might be a combination of a country, variable and year. Any additional information, like the full and official name of the country, could be stored in a supplementary table and consulted only at need. \n",
    "\n",
    "That’s the most efficient way. But every user and application is slightly different. As noted above, typically what we need for statistical analysis is a single case on each row, and a set of variables in the columns. Our case is a country, and our variables are things like GDP and population as described above in my example choice of variables. This involves some restructuring of the data which we clearly don’t want to do by hand. Pandas is your best friend here. \n",
    "\n",
    "Reshaping data is a two-step process of melting and pivoting the data. Melting the data involves describing which data are indicators (\"id\") and which are variables for retrieval (“measure”). In this case your data may already be in melted form (long form). Pivoting then involves actually reshaping the data into the needed format. In this step, you have to reshape the data from long to wide format.\n",
    " \n",
    "Pivoting the data involves specifying what data is on the rows and on the columns. Hint: functions melt and pivot offered by ``numpy`` library in python. For our analyses we want “Country.Code” to be on the rows, and to have all 4-7 variables as columns, where the value of each cell is the value taken from the column year that you chose at the subsetting step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise: Reshape the Data``\n",
    "\n",
    "- Examine the dimensions of the new pivoted data that you have created. Show it to us using head or print commands.\n",
    "- Then rename all column names to something better and useful, by replacing codes with their names or shorthand names (ex. AG.LND.TOTL.UR.K2 ---> Urban Land Area).  \n",
    "- Sort the data by putting higher values for one indicator of your choice go first. If there are overlapping values, try to put chronological countries go first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Reshape the Data</h3>\n",
    "\n",
    "As the next step, I decided to reshape my data first, before I look at any missing data. Having the indicators on the columns will simplify the process of looking for missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator Code  NY.GDP.MKTP.CD  SE.ADT.LITR.ZS  SH.MED.BEDS.ZS  \\\n",
      "Country Code                                                     \n",
      "ABW               2.453631e+09       96.822639             NaN   \n",
      "AFE               8.604783e+11             NaN             NaN   \n",
      "AFG               1.585668e+10             NaN            0.43   \n",
      "AFW               5.915958e+11             NaN             NaN   \n",
      "AGO               8.169956e+10             NaN             NaN   \n",
      "\n",
      "Indicator Code  SH.UHC.SRVS.CV.XD  SI.POV.GINI  SP.DYN.LE00.IN  \\\n",
      "Country Code                                                     \n",
      "ABW                           NaN          NaN       75.017000   \n",
      "AFE                           NaN          NaN       58.470697   \n",
      "AFG                          28.0          NaN       61.028000   \n",
      "AFW                           NaN          NaN       54.144307   \n",
      "AGO                          32.0          NaN       55.350000   \n",
      "\n",
      "Indicator Code  per_si_allsi.cov_pop_tot  \n",
      "Country Code                              \n",
      "ABW                                  NaN  \n",
      "AFE                                  NaN  \n",
      "AFG                                  NaN  \n",
      "AFW                                  NaN  \n",
      "AGO                                  NaN  \n"
     ]
    }
   ],
   "source": [
    "# create the pivoted dataframe bringing the indicator codes to the columns\n",
    "wdi_data_subset_2010_pivot = (wdi_data_subset_for_selected_year.pivot(index='Country Code', columns='Indicator Code', values=year_with_most_values))\n",
    "print(wdi_data_subset_2010_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country Code\n",
       "ABW     NaN\n",
       "AFE     NaN\n",
       "AFG     NaN\n",
       "AFW     NaN\n",
       "AGO     NaN\n",
       "       ... \n",
       "XKX    33.3\n",
       "YEM     NaN\n",
       "ZAF    63.4\n",
       "ZMB    55.6\n",
       "ZWE     NaN\n",
       "Name: SI.POV.GINI, Length: 266, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdi_data_subset_2010_pivot['SI.POV.GINI']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 266 entries, ABW to ZWE\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                                      Non-Null Count  Dtype  \n",
      "---  ------                                                      --------------  -----  \n",
      " 0   GDP (current US$)                                           256 non-null    float64\n",
      " 1   Literacy rate, adult total (% of people ages 15 and above)  91 non-null     float64\n",
      " 2   Hospital beds (per 1,000 people)                            171 non-null    float64\n",
      " 3   UHC service coverage index                                  204 non-null    float64\n",
      " 4   GINI index (World Bank estimate)                            84 non-null     float64\n",
      " 5   Life expectancy at birth, total (years)                     248 non-null    float64\n",
      " 6   per_si_allsi.cov_pop_tot                                    32 non-null     float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 16.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "indicator_code_to_text = {\n",
    "    'SP.DYN.LE00.IN': 'Life expectancy at birth, total (years)',\n",
    "    'SH.UHC.SRVS.CV.XD': 'UHC service coverage index',\n",
    "    'NY.GDP.MKTP.CD': 'GDP (current US$)',\n",
    "    'SI.POV.GINI': 'GINI index (World Bank estimate)',\n",
    "    'SE.ADT.LITR.ZS': 'Literacy rate, adult total (% of people ages 15 and above)',\n",
    "    'SH.MED.BEDS.ZS': 'Hospital beds (per 1,000 people)'\n",
    "}\n",
    "wdi_data_subset_2010_pivot = (wdi_data_subset_2010_pivot.rename(columns=indicator_code_to_text))\n",
    "print(wdi_data_subset_2010_pivot.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Task 3: Manage Missing Data``\n",
    "\n",
    "There is a lot of missing data. If you make the year on which you search too recent, many countries have not been able to report their data. If you make the year too long ago, the practice of administrative data collection had not yet taken hold. Countries did not know that collecting data would be a good thing; furthermore they have yet to back-fill their records. \n",
    "\n",
    "Why is data not available or missing in this dataset?\n",
    "The data availability for urbanisation is especially limited. The urbanisation variable in particular ``AG.LND.TOTL.UR.K2`` is only available per decade. The most recent populated data for this example variable is therefore 2010, in variable ``2010``.\n",
    "It’s quite possible that the World Bank is constructing estimates of urbanisation out of complex data sources such as satellite imagery. Regardless, it appears expensive to compute, and is therefore only offered every decade. \n",
    "\n",
    "We’ve got a number of ways in general of dealing with missing data. These involve\n",
    "\n",
    "1. Dropping off cases (or rows) in the data with any missing variables\n",
    "2. Excluding variables in the data with any missing data \n",
    "3. Selectively choosing indicators with only a limited amount of missing data\n",
    "4. Replacing missing variables with averages, or other representative values\n",
    "5. Creating a separate model to predict missing data\n",
    "\n",
    "In this assignment we are going to use a number of these strategies. We can certainly be dropping off cases (strategy one). I am loathe to drop off whole indicators. But we can, for example, choose a year for the indicator where most of the data is available (strategy three).\n",
    "\n",
    "Building a separate model to impute missing data, is often a good idea. But that requires a first working model before we even consider building a missing data model (and we haven't got there yet in this course); the working model and the missing data model are often constructed together. Note also that there are packages in Python which will construct a model of your data, and then impute missing values for you. You may or may not find these functions and packaging for modelling your data to be fully appropriate. Therefore treat these missing data models very seriously, and not as a black box. Models of missing data are as important, and deserve just as much care and caution as any other statistical model.  \n",
    "\n",
    "In the next section I discuss some specifics about how the data is currently formatted, and how we would like to have it formatted for analysis purposes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise: Manage Missing Data``\n",
    "\n",
    "We’ve got a number of ways in general of dealing with missing data. These involve\n",
    "\n",
    "1. Dropping off cases (or rows) in the data with any missing variables\n",
    "2. Excluding variables in the data with any missing data \n",
    "3. Selectively choosing indicators with only a limited amount of missing data\n",
    "4. Replacing missing variables with averages, or other representative values\n",
    "5. Creating a separate model to predict missing data\n",
    "\n",
    "- Count the missing values in each column\n",
    "- Manage the missing values (delete or replace values or leave them as they are) and briefly explain your choice for each column using comments or markdown text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1862 entries, 243 to 383516\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Country Name    1862 non-null   object \n",
      " 1   Country Code    1862 non-null   object \n",
      " 2   Indicator Name  1862 non-null   object \n",
      " 3   Indicator Code  1862 non-null   object \n",
      " 4   2010            1086 non-null   float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 87.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# use many cells if you like to structure your code well\n",
    "print(wdi_data_subset_for_selected_year.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1862 entries, 243 to 383516\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Country Name    1862 non-null   object \n",
      " 1   Country Code    1862 non-null   object \n",
      " 2   Indicator Name  1862 non-null   object \n",
      " 3   Indicator Code  1862 non-null   object \n",
      " 4   2010            1086 non-null   float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 87.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wdi_data_subset_2010 = wdi_data_subset_for_selected_year.dropna()\n",
    "print(wdi_data_subset_for_selected_year.info())\n",
    "\n",
    "#drop them because Gini coefficent cannot be set to 0 - it is a measure of inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "***\n",
    "\n",
    "# ``Task 5: Saving the Results``\n",
    "\n",
    "_Note:_ We do not need this file but we expect that if you learn how to save your data, it will be very useful in the future, as you do not need to run the script to clean your data again. \n",
    "\n",
    "## ``Exercise: Saving the Results``\n",
    "- Save the cleaned dataframe as 'assignment-01-cleaned.csv' in data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_data_subset_2010_pivot.to_csv('data/WDIData_2010.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
