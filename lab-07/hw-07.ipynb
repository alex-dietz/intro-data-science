{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 200px\" src=\"https://raw.githubusercontent.com/trivikverma/researchgroup/master/assets/media/logo.png\"> EPA-1316A Introduction to *Urban* Data Science  \n",
    "\n",
    "\n",
    "## Homework 7: Points, Spatial Density Estimation\n",
    "\n",
    "**TU Delft**<br>\n",
    "**Q1 2022**<br>\n",
    "**Instructor:** Trivik Verma <br>\n",
    "**TAs:** Auriane Técourt, Dorukhan Yeşilli, Ludovica Bindi, Nicolò Canal, Ruth Nelson, Vaibhavi Srivastava <br>\n",
    "**[Centre for Urban Science & Policy]( https://cusp.tbm.tudelft.nl/)** <br>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, geopandas, contextily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task I: AirBnb distribution in Beijing\n",
    "\n",
    "In this task, you will explore patterns in the distribution of the location of AirBnb properties in Beijing. For that, we will use data from the same provider as we did for the clustering block: [Inside AirBnb](https://insideairbnb.com). We are going to read in a file with the locations of the properties available as of August 15th. 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"http://data.insideairbnb.com/china/beijing/beijing/\"\\\n",
    "       \"2021-07-17/visualisations/listings.csv\")\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Important`\n",
    "Make sure you are connected to the internet when you run this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abb = pandas.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a table with the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, for an ancillary geography, we will use the neighbourhoods provided by the same source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"http://data.insideairbnb.com/china/beijing/beijing/\"\\\n",
    "       \"2021-07-17/visualisations/neighbourhoods.geojson\")\n",
    "url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Important`\n",
    "Make sure you are connected to the internet when you run this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neis = geopandas.read_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neis.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these at hand, get to work with the following challenges:\n",
    "\n",
    "* Create a Hex binning map of the property locations\n",
    "* Compute and display a kernel density estimate (KDE) of the distribution of the properties\n",
    "* Using the neighbourhood layer:\n",
    "    * Obtain a count of property by neighbourhood (the neighbourhood name is present in the property table and you can connect the two tables through that)\n",
    "    * Create a raw count choropleth\n",
    "    * Create a choropleth of the density of properties by polygon\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task II: Clusters of Indian cities\n",
    "\n",
    "For this one, we are going to use a dataset on the location of populated places in India provided by [`https://geojson.xyz`](geojson.xyz). The original table covers the entire world so, to get it ready for you to work on it, we need to prepare it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://d2ad6b4ur7yvpq.cloudfront.net/naturalearth-3.3.0/\"\\\n",
    "       \"ne_50m_populated_places_simple.geojson\")\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's read the file in and keep only places from India:\n",
    "\n",
    "`Important`\n",
    "Make sure you are connected to the internet when you run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = geopandas.read_file(url).query(\"adm0name == 'India'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By defaul, place locations come expressed in longitude and latitude. Because you will be working with distances, it makes sense to convert the table into a system expressed in metres. For India, this can be the [\"Kalianpur 1975 / India zone I\"](http://epsg.io/24378) (`EPSG:24378`) projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_m = places.to_crs(epsg=24378)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we have to work with then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = places_m.plot(color=\"xkcd:bright yellow\",\n",
    "                 figsize=(9, 9)\n",
    "                )\n",
    "contextily.add_basemap(ax, \n",
    "                       crs=places_m.crs,\n",
    "                       source=contextily.providers.CartoDB.DarkMatter\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this at hand, get to work:\n",
    "\n",
    "- Use the DBSCAN algorithm to identify clusters\n",
    "- Start with the following parameters: at least five cities for a cluster (`min_samples`) and a maximum of 1,000Km (`eps`)\n",
    "- Obtain the clusters and plot them on a map. *Does it pick up any interesting pattern?*\n",
    "- Based on the results above, tweak the values of both parameters to find a cluster of southern cities, and another one of cities in the North around New Dehli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
